{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"682f6c6092da45fdbb200f98cd15d2d8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6a82df6d5c0e47188678c0e214330024","IPY_MODEL_04c5cd66d04f488e9877887a43f6a71b","IPY_MODEL_ea2d3c19ffd3476ba255982fb18efc72"],"layout":"IPY_MODEL_1801de1628dd4b1e8d17b98d593347b4"}},"6a82df6d5c0e47188678c0e214330024":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5ac9ad696af1458bb0332a99aceafe7d","placeholder":"​","style":"IPY_MODEL_560d33b57d064b039d816f24512c5c26","value":"Downloading (…)lve/main/config.json: 100%"}},"04c5cd66d04f488e9877887a43f6a71b":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_1c47eb3a2faa4d56a2759718f5e34e65","max":638,"min":0,"orientation":"horizontal","style":"IPY_MODEL_449a3e3fd452436abff4883e7434e511","value":638}},"ea2d3c19ffd3476ba255982fb18efc72":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50eb758768a64860a3938fa3c1202292","placeholder":"​","style":"IPY_MODEL_32d45ebcccb2432baea420fcc79c4982","value":" 638/638 [00:00&lt;00:00, 23.8kB/s]"}},"1801de1628dd4b1e8d17b98d593347b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5ac9ad696af1458bb0332a99aceafe7d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"560d33b57d064b039d816f24512c5c26":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"1c47eb3a2faa4d56a2759718f5e34e65":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"449a3e3fd452436abff4883e7434e511":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"50eb758768a64860a3938fa3c1202292":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"32d45ebcccb2432baea420fcc79c4982":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"39de89af9fca4efaacf0c24ccefbe7d7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_3ce945601a1f43c48a6efa3f2f8aea54","IPY_MODEL_39303dd16e484d2599d2f3beab366585","IPY_MODEL_52a8f05097c540b99e14c7af200b4a71"],"layout":"IPY_MODEL_0f3afbddc2b548e0a5776de56cd32e52"}},"3ce945601a1f43c48a6efa3f2f8aea54":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_4d5dc5bbc5b44b3ca1c9d83dfb9c6b9c","placeholder":"​","style":"IPY_MODEL_24e96152db7e4c5b9abfc1c4ea97d347","value":"Downloading pytorch_model.bin: 100%"}},"39303dd16e484d2599d2f3beab366585":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f9100fb922ac482fbfd44a49748b6ff6","max":891689589,"min":0,"orientation":"horizontal","style":"IPY_MODEL_108a0db7feb746b5b6bf7313f2a8d491","value":891689589}},"52a8f05097c540b99e14c7af200b4a71":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_489e7e40de12415c9fcc68b5af253c38","placeholder":"​","style":"IPY_MODEL_e74f623900da4a70acebfce8d99a8e54","value":" 892M/892M [00:15&lt;00:00, 60.8MB/s]"}},"0f3afbddc2b548e0a5776de56cd32e52":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4d5dc5bbc5b44b3ca1c9d83dfb9c6b9c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"24e96152db7e4c5b9abfc1c4ea97d347":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f9100fb922ac482fbfd44a49748b6ff6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"108a0db7feb746b5b6bf7313f2a8d491":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"489e7e40de12415c9fcc68b5af253c38":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e74f623900da4a70acebfce8d99a8e54":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f27e31fd734644248bbb1c4b75f26ecf":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_048982b39273448fbab6ac83d4796d1e","IPY_MODEL_3d244c40db0c4639bf161b618026dc30","IPY_MODEL_88dae6916890412da4c68df368457718"],"layout":"IPY_MODEL_860483f584e048dca0bdd02af2d49d92"}},"048982b39273448fbab6ac83d4796d1e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_52364c842fdf403aa4aaff930416ace1","placeholder":"​","style":"IPY_MODEL_8f0e5403b7a44d2b842bfda40a1a1715","value":"Downloading builder script: "}},"3d244c40db0c4639bf161b618026dc30":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_595d932a86d24e37a22c53e93d1b4069","max":2849,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5971843c25b4451db83a257a08d5c423","value":2849}},"88dae6916890412da4c68df368457718":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_7a0798b553504bcf8a53c9a4ea751ae9","placeholder":"​","style":"IPY_MODEL_0fa3fad76ecc4ca0b2413bdae0190acb","value":" 7.65k/? [00:00&lt;00:00, 393kB/s]"}},"860483f584e048dca0bdd02af2d49d92":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"52364c842fdf403aa4aaff930416ace1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8f0e5403b7a44d2b842bfda40a1a1715":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"595d932a86d24e37a22c53e93d1b4069":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5971843c25b4451db83a257a08d5c423":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7a0798b553504bcf8a53c9a4ea751ae9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"0fa3fad76ecc4ca0b2413bdae0190acb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["# **Fine Tuning Transformer for Neural Machine Translation**"],"metadata":{"id":"KbrKA-CD0bV6"}},{"cell_type":"markdown","source":["## *What is Machine Translation ?*"],"metadata":{"id":"B2a3MTVUe_Lr"}},{"cell_type":"markdown","source":["*Machine translation is a field that focuses on using automated systems to convert text or speech from one language to another. By Leveraging various techniques, such as computational models and linguistic analysis, machine translation aim to overcome language barriers and facilitate communication across different languages. The goals is to achieve accurate and fluid translations through the use of sophisticated algorithms and large-scale data processing*"],"metadata":{"id":"ff3k6Zn3e-CX"}},{"cell_type":"markdown","source":["## *What is Satistical Machine Translation (SMT) ?!*"],"metadata":{"id":"IakLjkjix-Cg"}},{"cell_type":"markdown","source":["*Statistical Machine translation is an approach within machine translation that relies on statistical models and vast amounts of bilingual text data. Unlike rule-based methods, SMT works by analyzing patterns and relationships between words or pharses in the source and target languages. By training on large corpora, SMT models estimate the probability of translation choices and generate output based on statistical likelihood. SMT has been widely used and has shown success in achieving acceptable translation quality for numerous language pairs.*"],"metadata":{"id":"sqnPvL3Mx96J"}},{"cell_type":"markdown","source":["## *What is Neural Machine Learning (NMT) ?!*"],"metadata":{"id":"UtEgDhFlx9qh"}},{"cell_type":"markdown","source":["*Neural machine translation is a modern approach to machine translation that utilizes artifical neural networks, particularly recurrent nerual networks (RNNs) or transformer models. NMT systems operate on a more holistic level, learning to capture the contextual meaning of the input text and generating translations based on this understanding. By leveraging the power of neural networks, NMT models excel at capturing long-range dependencies and producing coherent and fluent translations. This approach has surpassed traditional methods in terms of translation quality and has become the prevailing paradigm in machine translation research and development.*"],"metadata":{"id":"Bofciq-hx9f9"}},{"cell_type":"markdown","source":["## Reference Links for below code"],"metadata":{"id":"33fa5ncs05fe"}},{"cell_type":"markdown","source":["\n","\n","1.   [Google Colab](https://colab.research.google.com/drive/1ge0aqzAbCRWS7CJIbdDVPk-NBBSxjKlv#scrollTo=biPo8vFTx5Ue)\n","2.  [Medium Article](https://medium.com/@tskumar1320/how-to-fine-tune-pre-trained-language-translation-model-3e8a6aace9f)\n","3. [HuggingFace Documentation](https://huggingface.co/docs/transformers/model_doc/t5)\n","4. [HuggingFace FineTuning Tips ](https://discuss.huggingface.co/t/t5-finetuning-tips/684)\n","\n","\n"],"metadata":{"id":"aifqxZMa1Ay0"}},{"cell_type":"markdown","source":["## Installing Dependencies"],"metadata":{"id":"FnQJxZDy31cJ"}},{"cell_type":"code","source":["! pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org <package_name>\n","! pip install datasets sacrebleu torch transformers sentencepiece transformers[sentencepiece]\n","! pip install accelerate -U"],"metadata":{"id":"48w_mciC32LV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702830880962,"user_tz":-60,"elapsed":29255,"user":{"displayName":"HAMZA BOUKTITIYA","userId":"05385177150877535559"}},"outputId":"bc91d20f-c7f8-4f01-cc10-435e2132ae7e"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: -c: line 1: syntax error near unexpected token `newline'\n","/bin/bash: -c: line 1: ` pip install --trusted-host pypi.org --trusted-host pypi.python.org --trusted-host files.pythonhosted.org <package_name>'\n","Collecting datasets\n","  Using cached datasets-2.15.0-py3-none-any.whl (521 kB)\n","Collecting sacrebleu\n","  Using cached sacrebleu-2.4.0-py3-none-any.whl (106 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n","Collecting sentencepiece\n","  Using cached sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n","Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (10.0.1)\n","Collecting pyarrow-hotfix (from datasets)\n","  Using cached pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n","Collecting dill<0.3.8,>=0.3.0 (from datasets)\n","  Using cached dill-0.3.7-py3-none-any.whl (115 kB)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n","Collecting multiprocess (from datasets)\n","  Using cached multiprocess-0.70.15-py310-none-any.whl (134 kB)\n","Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.1)\n","Requirement already satisfied: huggingface-hub>=0.18.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.19.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n","Collecting portalocker (from sacrebleu)\n","  Using cached portalocker-2.8.2-py3-none-any.whl (17 kB)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (2023.6.3)\n","Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (0.9.0)\n","Collecting colorama (from sacrebleu)\n","  Using cached colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n","Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from sacrebleu) (4.9.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n","Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.1)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from transformers) (3.20.3)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.11.17)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n","Installing collected packages: sentencepiece, pyarrow-hotfix, portalocker, dill, colorama, sacrebleu, multiprocess, datasets\n","Successfully installed colorama-0.4.6 datasets-2.15.0 dill-0.3.7 multiprocess-0.70.15 portalocker-2.8.2 pyarrow-hotfix-0.6 sacrebleu-2.4.0 sentencepiece-0.1.99\n","Collecting accelerate\n","  Downloading accelerate-0.25.0-py3-none-any.whl (265 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.7/265.7 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.23.5)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n","Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.19.4)\n","Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n","Installing collected packages: accelerate\n","Successfully installed accelerate-0.25.0\n"]}]},{"cell_type":"markdown","source":["## Required Imports"],"metadata":{"id":"kg8fUQ6s4a3C"}},{"cell_type":"code","source":["import warnings\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","import transformers\n","\n","from datasets import Dataset\n","from datasets import load_metric\n","\n","from tqdm import tqdm\n","from transformers import AutoTokenizer\n","from sklearn.model_selection import train_test_split\n","from transformers import T5Tokenizer, T5ForConditionalGeneration, AutoModelForSeq2SeqLM\n","from transformers import DataCollatorForSeq2Seq, Seq2SeqTrainingArguments, Seq2SeqTrainer\n","\n","warnings.filterwarnings(\"ignore\")"],"metadata":{"id":"cNlIP_ZMxlVr","executionInfo":{"status":"ok","timestamp":1702830917076,"user_tz":-60,"elapsed":366,"user":{"displayName":"HAMZA BOUKTITIYA","userId":"05385177150877535559"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["## Constants"],"metadata":{"id":"fNUZoUK15nXw"}},{"cell_type":"code","source":["BATCH_SIZE = 16\n","BLEU = \"bleu\"\n","ENGLISH = \"en\"\n","ENGLISH_TEXT = \"english_text\"\n","EPOCH = \"epoch\"\n","INPUT_IDS = \"input_ids\"\n","FILENAME = \"TranslationDataset.csv\"\n","GEN_LEN = \"gen_len\"\n","MAX_INPUT_LENGTH = 128\n","MAX_TARGET_LENGTH = 128\n","MODEL_CHECKPOINT = \"unicamp-dl/translation-pt-en-t5\"\n","MODEL_NAME = MODEL_CHECKPOINT.split(\"/\")[-1]\n","LABELS = \"labels\"\n","PREFIX = \"\"\n","PORTUGUESE = \"pt\"\n","PORTUGUESE_TEXT = \"portuguese_text\"\n","SCORE = \"score\"\n","SOURCE_LANG = \"pt\"\n","TARGET_LANG = \"en\"\n","TRANSLATION = \"translation\"\n","UNNAMED_COL = \"Unnamed: 0\""],"metadata":{"id":"AxJjKdbI5laC","executionInfo":{"status":"ok","timestamp":1702830923608,"user_tz":-60,"elapsed":351,"user":{"displayName":"HAMZA BOUKTITIYA","userId":"05385177150877535559"}}},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":["## Helper Functions"],"metadata":{"id":"oc6KkkKw62_A"}},{"cell_type":"code","source":["def postprocess_text(preds: list, labels: list) -> tuple:\n","    \"\"\"Performs post processing on the prediction text and labels\"\"\"\n","\n","    preds = [pred.strip() for pred in preds]\n","    labels = [[label.strip()] for label in labels]\n","\n","    return preds, labels\n","\n","\n","def prep_data_for_model_fine_tuning(source_lang: list, target_lang: list) -> list:\n","    \"\"\"Takes the input data lists and converts into translation list of dicts\"\"\"\n","    PORTUGUESE='darija'\n","    ENGLISH='english'\n","\n","    data_dict = dict()\n","    data_dict[TRANSLATION] = []\n","\n","    for sr_text, tr_text in zip(source_lang, target_lang):\n","        temp_dict = dict()\n","        temp_dict[PORTUGUESE] = sr_text\n","        temp_dict[ENGLISH] = tr_text\n","\n","        data_dict[TRANSLATION].append(temp_dict)\n","\n","    return data_dict\n","\n","\n","def generate_model_ready_dataset1(dataset: list, source: str, target: str,\n","                                 model_checkpoint: str,\n","                                 tokenizer: AutoTokenizer):\n","    \"\"\"Makes the data training ready for the model\"\"\"\n","\n","    preped_data = []\n","\n","    for row in dataset:\n","        inputs = PREFIX + row[source]\n","        targets = row[target]\n","\n","        model_inputs = tokenizer(inputs, max_length=MAX_INPUT_LENGTH,\n","                                 truncation=True, padding=True)\n","\n","        model_inputs[TRANSLATION] = row\n","\n","        # setup the tokenizer for targets\n","        with tokenizer.as_target_tokenizer():\n","            labels = tokenizer(targets, max_length=MAX_INPUT_LENGTH,\n","                                 truncation=True, padding=True)\n","            model_inputs[LABELS] = labels[INPUT_IDS]\n","\n","        preped_data.append(model_inputs)\n","\n","    return preped_data\n","\n","def generate_model_ready_dataset(dataset: list, source: str, target: str,\n","                                 model_checkpoint: str,\n","                                 tokenizer: AutoTokenizer):\n","    \"\"\"Makes the data training ready for the model\"\"\"\n","\n","    preped_data = []\n","\n","    for row in dataset:\n","        inputs = PREFIX + row[source]  # Assuming source is 'darija'\n","        targets = row[target]  # Assuming target is 'english'\n","\n","        model_inputs = tokenizer(inputs, max_length=MAX_INPUT_LENGTH,\n","                                 truncation=True, padding=True)\n","\n","        model_inputs[TRANSLATION] = row\n","\n","        # Setup the tokenizer for targets\n","        with tokenizer.as_target_tokenizer():\n","            labels = tokenizer(targets, max_length=MAX_INPUT_LENGTH,\n","                               truncation=True, padding=True)\n","            model_inputs[LABELS] = labels[INPUT_IDS]\n","\n","        preped_data.append(model_inputs)\n","\n","    return preped_data\n","\n","\n","def compute_metrics(eval_preds: tuple) -> dict:\n","    \"\"\"computes bleu score and other performance metrics \"\"\"\n","\n","    metric = load_metric(\"sacrebleu\")\n","    tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)\n","\n","    preds, labels = eval_preds\n","\n","    if isinstance(preds, tuple):\n","        preds = preds[0]\n","\n","    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n","\n","    # Replace -100 in the labels as we can't decode them.\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    # Some simple post-processing\n","    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n","\n","    result = metric.compute(predictions=decoded_preds, references=decoded_labels)\n","    result = {BLEU: result[SCORE]}\n","\n","    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n","\n","    result[GEN_LEN] = np.mean(prediction_lens)\n","    result = {k: round(v, 4) for k, v in result.items()}\n","\n","    return result"],"metadata":{"id":"OqFwKnxI62pw","executionInfo":{"status":"ok","timestamp":1702831506829,"user_tz":-60,"elapsed":348,"user":{"displayName":"HAMZA BOUKTITIYA","userId":"05385177150877535559"}}},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":["## Loading and Preparing The Dataset"],"metadata":{"id":"ETkGlFxq63bj"}},{"cell_type":"code","source":["translation_data = pd.read_csv('/content/sentences.csv')\n","#translation_data = translation_data.drop([UNNAMED_COL], axis=1)\n","translation_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"IblRC-sVxBSe","outputId":"17530150-823d-403c-8917-f4d65471b2f8","executionInfo":{"status":"ok","timestamp":1702830925736,"user_tz":-60,"elapsed":13,"user":{"displayName":"HAMZA BOUKTITIYA","userId":"05385177150877535559"}}},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                 english  \\\n","0                    They're hiding something, I'm sure!   \n","1        It's obvious they're trying to keep their cool.   \n","2                the hotels don't seem very comfortable.   \n","3      he is probably about to be laid off by head of...   \n","4                             of course he's depressive!   \n","...                                                  ...   \n","9996                          There is no homework today   \n","9997                                  Back to your place   \n","9998                               Did you miss the bus?   \n","9999                                Who is absent today?   \n","10000                                       Stop talking   \n","\n","                                       darija  \n","0        homa mkhbbyin chi haja, ana mti99en!  \n","1          bayna homa tay7awlo ib9aw mbrrdin.  \n","2      loTilat mabaynach fihom mori7in bzzaf.  \n","3          ghaliban ghayjrriw 3lih mn lkhdma!  \n","4                         Tab3an rah mkta2eb!  \n","...                                       ...  \n","9996                  makaynch ttamarin lyoum  \n","9997                            rje3 lblaStek  \n","9998                   wach mcha 3lik TTobis?  \n","9999                   chkoun tgheyyeb lyoum?  \n","10000                        baraka mn l8eDra  \n","\n","[10001 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-e83fea5b-f43e-436b-bd54-e462336a5ed1\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>english</th>\n","      <th>darija</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>They're hiding something, I'm sure!</td>\n","      <td>homa mkhbbyin chi haja, ana mti99en!</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>It's obvious they're trying to keep their cool.</td>\n","      <td>bayna homa tay7awlo ib9aw mbrrdin.</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>the hotels don't seem very comfortable.</td>\n","      <td>loTilat mabaynach fihom mori7in bzzaf.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>he is probably about to be laid off by head of...</td>\n","      <td>ghaliban ghayjrriw 3lih mn lkhdma!</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>of course he's depressive!</td>\n","      <td>Tab3an rah mkta2eb!</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>9996</th>\n","      <td>There is no homework today</td>\n","      <td>makaynch ttamarin lyoum</td>\n","    </tr>\n","    <tr>\n","      <th>9997</th>\n","      <td>Back to your place</td>\n","      <td>rje3 lblaStek</td>\n","    </tr>\n","    <tr>\n","      <th>9998</th>\n","      <td>Did you miss the bus?</td>\n","      <td>wach mcha 3lik TTobis?</td>\n","    </tr>\n","    <tr>\n","      <th>9999</th>\n","      <td>Who is absent today?</td>\n","      <td>chkoun tgheyyeb lyoum?</td>\n","    </tr>\n","    <tr>\n","      <th>10000</th>\n","      <td>Stop talking</td>\n","      <td>baraka mn l8eDra</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>10001 rows × 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e83fea5b-f43e-436b-bd54-e462336a5ed1')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-e83fea5b-f43e-436b-bd54-e462336a5ed1 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-e83fea5b-f43e-436b-bd54-e462336a5ed1');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-3fc55987-3399-41a9-84c1-d7ff91ba555f\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-3fc55987-3399-41a9-84c1-d7ff91ba555f')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-3fc55987-3399-41a9-84c1-d7ff91ba555f button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["## Train, Test & Validation Split of Data"],"metadata":{"id":"0y0sf7sxEoyn"}},{"cell_type":"code","source":["X = translation_data['darija']\n","y = translation_data['english']"],"metadata":{"id":"yXkgqG7Oxn8U","executionInfo":{"status":"ok","timestamp":1702830927677,"user_tz":-60,"elapsed":386,"user":{"displayName":"HAMZA BOUKTITIYA","userId":"05385177150877535559"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.10,\n","                                                    shuffle=True,\n","                                                    random_state=100)\n","\n","print(\"INITIAL X-TRAIN SHAPE: \", x_train.shape)\n","print(\"INITIAL Y-TRAIN SHAPE: \", y_train.shape)\n","print(\"X-TEST SHAPE: \", x_test.shape)\n","print(\"Y-TEST SHAPE: \", y_test.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sE7Mh3gIFKCe","outputId":"780f9da8-c4d7-46c0-c131-dc2397377b98","executionInfo":{"status":"ok","timestamp":1702830928028,"user_tz":-60,"elapsed":4,"user":{"displayName":"HAMZA BOUKTITIYA","userId":"05385177150877535559"}}},"execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["INITIAL X-TRAIN SHAPE:  (9000,)\n","INITIAL Y-TRAIN SHAPE:  (9000,)\n","X-TEST SHAPE:  (1001,)\n","Y-TEST SHAPE:  (1001,)\n"]}]},{"cell_type":"code","source":["x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,\n","                                                  test_size=0.20,\n","                                                  shuffle=True,\n","                                                  random_state=100)\n","\n","print(\"FINAL X-TRAIN SHAPE: \", x_train.shape)\n","print(\"FINAL Y-TRAIN SHAPE: \", y_train.shape)\n","print(\"X-VAL SHAPE: \", x_val.shape)\n","print(\"Y-VAL SHAPE: \", y_val.shape)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IxGyZD6aFZsf","outputId":"3da317e6-2027-4da9-a3cb-07ed5450f0ea","executionInfo":{"status":"ok","timestamp":1702830928738,"user_tz":-60,"elapsed":8,"user":{"displayName":"HAMZA BOUKTITIYA","userId":"05385177150877535559"}}},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["FINAL X-TRAIN SHAPE:  (7200,)\n","FINAL Y-TRAIN SHAPE:  (7200,)\n","X-VAL SHAPE:  (1800,)\n","Y-VAL SHAPE:  (1800,)\n"]}]},{"cell_type":"markdown","source":["## Load Tokenizer from AutoTokenizer Class"],"metadata":{"id":"qg1a8Z-7HDtB"}},{"cell_type":"code","source":["tokenizer = AutoTokenizer.from_pretrained(MODEL_CHECKPOINT)"],"metadata":{"id":"BJ3QS5QQHDTn","executionInfo":{"status":"ok","timestamp":1702830932617,"user_tz":-60,"elapsed":1347,"user":{"displayName":"HAMZA BOUKTITIYA","userId":"05385177150877535559"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["## Prepare the model ready dataset"],"metadata":{"id":"MuVPSP6OGYd5"}},{"cell_type":"code","source":["training_data = prep_data_for_model_fine_tuning(x_train.values, y_train.values)\n","\n","validation_data = prep_data_for_model_fine_tuning(x_val.values, y_val.values)\n","\n","test_data = prep_data_for_model_fine_tuning(x_test.values, y_test.values)"],"metadata":{"id":"lXmGr3ZdGGUw","executionInfo":{"status":"ok","timestamp":1702830936982,"user_tz":-60,"elapsed":291,"user":{"displayName":"HAMZA BOUKTITIYA","userId":"05385177150877535559"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["train_data = generate_model_ready_dataset(dataset=training_data[TRANSLATION],\n","                                          tokenizer=tokenizer,\n","                                          source=PORTUGUESE,\n","                                          target=ENGLISH,\n","                                          model_checkpoint=MODEL_CHECKPOINT)\n","\n","validation_data = generate_model_ready_dataset(dataset=validation_data[TRANSLATION],\n","                                               tokenizer=tokenizer,\n","                                               source=PORTUGUESE,\n","                                               target=ENGLISH,\n","                                               model_checkpoint=MODEL_CHECKPOINT)\n","\n","test_data = generate_model_ready_dataset(dataset=test_data[TRANSLATION],\n","                                               tokenizer=tokenizer,\n","                                               source=PORTUGUESE,\n","                                               target=ENGLISH,\n","                                               model_checkpoint=MODEL_CHECKPOINT)"],"metadata":{"id":"A-9mGj0EHZOg","colab":{"base_uri":"https://localhost:8080/","height":394},"executionInfo":{"status":"error","timestamp":1702831518562,"user_tz":-60,"elapsed":395,"user":{"displayName":"HAMZA BOUKTITIYA","userId":"05385177150877535559"}},"outputId":"d0a691b2-ff8b-4a9c-d993-a7efbddcbda6"},"execution_count":31,"outputs":[{"output_type":"error","ename":"KeyError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-25e0180cabf7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_data = generate_model_ready_dataset(dataset=training_data[TRANSLATION],\n\u001b[0m\u001b[1;32m      2\u001b[0m                                           \u001b[0mtokenizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                                           \u001b[0msource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPORTUGUESE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                                           \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mENGLISH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                           model_checkpoint=MODEL_CHECKPOINT)\n","\u001b[0;32m<ipython-input-29-f2d86bc8c2dd>\u001b[0m in \u001b[0;36mgenerate_model_ready_dataset\u001b[0;34m(dataset, source, target, model_checkpoint, tokenizer)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPREFIX\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msource\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Assuming source is 'darija'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m  \u001b[0;31m# Assuming target is 'english'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'pt'"]}]},{"cell_type":"code","source":["train_df = pd.DataFrame.from_records(train_data)\n","train_df.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NvWOVbFAID4G","outputId":"01cbcded-9e49-43a8-f82e-0f72b4a44d6e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 478 entries, 0 to 477\n","Data columns (total 4 columns):\n"," #   Column          Non-Null Count  Dtype \n","---  ------          --------------  ----- \n"," 0   attention_mask  478 non-null    object\n"," 1   input_ids       478 non-null    object\n"," 2   labels          478 non-null    object\n"," 3   translation     478 non-null    object\n","dtypes: object(4)\n","memory usage: 15.1+ KB\n"]}]},{"cell_type":"code","source":["validation_df = pd.DataFrame.from_records(validation_data)\n","validation_df.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V6UMpNLYId9A","outputId":"444e349a-2277-42b6-cfbe-99f41a934d3b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 120 entries, 0 to 119\n","Data columns (total 4 columns):\n"," #   Column          Non-Null Count  Dtype \n","---  ------          --------------  ----- \n"," 0   attention_mask  120 non-null    object\n"," 1   input_ids       120 non-null    object\n"," 2   labels          120 non-null    object\n"," 3   translation     120 non-null    object\n","dtypes: object(4)\n","memory usage: 3.9+ KB\n"]}]},{"cell_type":"code","source":["test_df = pd.DataFrame.from_records(test_data)\n","test_df.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xRU2QpMlQA7T","outputId":"3a40795e-a836-41c5-f462-451476afeb99"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 67 entries, 0 to 66\n","Data columns (total 4 columns):\n"," #   Column          Non-Null Count  Dtype \n","---  ------          --------------  ----- \n"," 0   attention_mask  67 non-null     object\n"," 1   input_ids       67 non-null     object\n"," 2   labels          67 non-null     object\n"," 3   translation     67 non-null     object\n","dtypes: object(4)\n","memory usage: 2.2+ KB\n"]}]},{"cell_type":"markdown","source":["## Convert dataframe to Dataset Class object"],"metadata":{"id":"YWOlWvp4IvK6"}},{"cell_type":"code","source":["train_dataset = Dataset.from_pandas(train_df)\n","train_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jG4yBOVMImwn","outputId":"c208e421-4833-4822-ade0-dc5fc3ea58fa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['attention_mask', 'input_ids', 'labels', 'translation'],\n","    num_rows: 478\n","})"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["validation_dataset = Dataset.from_pandas(validation_df)\n","validation_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lZgO6Dx3I3k6","outputId":"795b9c5f-2b24-4cf5-8647-a5ff85619480"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['attention_mask', 'input_ids', 'labels', 'translation'],\n","    num_rows: 120\n","})"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["test_dataset = Dataset.from_pandas(test_df)\n","test_dataset"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rUcJXuHgQPUF","outputId":"9b2a15e6-5e24-4cf7-8efc-82d89043654c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Dataset({\n","    features: ['attention_mask', 'input_ids', 'labels', 'translation'],\n","    num_rows: 67\n","})"]},"metadata":{},"execution_count":18}]},{"cell_type":"markdown","source":["## Load model, Create Model Training Args and Data Collator"],"metadata":{"id":"A_y7dvANJK60"}},{"cell_type":"code","source":["model = AutoModelForSeq2SeqLM.from_pretrained(MODEL_CHECKPOINT)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":81,"referenced_widgets":["682f6c6092da45fdbb200f98cd15d2d8","6a82df6d5c0e47188678c0e214330024","04c5cd66d04f488e9877887a43f6a71b","ea2d3c19ffd3476ba255982fb18efc72","1801de1628dd4b1e8d17b98d593347b4","5ac9ad696af1458bb0332a99aceafe7d","560d33b57d064b039d816f24512c5c26","1c47eb3a2faa4d56a2759718f5e34e65","449a3e3fd452436abff4883e7434e511","50eb758768a64860a3938fa3c1202292","32d45ebcccb2432baea420fcc79c4982","39de89af9fca4efaacf0c24ccefbe7d7","3ce945601a1f43c48a6efa3f2f8aea54","39303dd16e484d2599d2f3beab366585","52a8f05097c540b99e14c7af200b4a71","0f3afbddc2b548e0a5776de56cd32e52","4d5dc5bbc5b44b3ca1c9d83dfb9c6b9c","24e96152db7e4c5b9abfc1c4ea97d347","f9100fb922ac482fbfd44a49748b6ff6","108a0db7feb746b5b6bf7313f2a8d491","489e7e40de12415c9fcc68b5af253c38","e74f623900da4a70acebfce8d99a8e54"]},"id":"i2Iivu_0I_YM","outputId":"f613f9a0-423a-4dc2-f14c-dd0e7dddfb84"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/638 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"682f6c6092da45fdbb200f98cd15d2d8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/892M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39de89af9fca4efaacf0c24ccefbe7d7"}},"metadata":{}}]},{"cell_type":"code","source":["model_args = Seq2SeqTrainingArguments(\n","    f\"{MODEL_NAME}-finetuned-{SOURCE_LANG}-to-{TARGET_LANG}\",\n","    evaluation_strategy=EPOCH,\n","    learning_rate=2e-4,\n","    per_device_train_batch_size=BATCH_SIZE,\n","    per_device_eval_batch_size=BATCH_SIZE,\n","    weight_decay=0.02,\n","    save_total_limit=3,\n","    num_train_epochs=10,\n","    predict_with_generate=True\n",")"],"metadata":{"id":"c_Gkhq1LJW4j"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"],"metadata":{"id":"W5kD6tLvK4Bx"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Fine Tuning the Model, finally !!"],"metadata":{"id":"EfkP8h4ZNBpo"}},{"cell_type":"code","source":["trainer = Seq2SeqTrainer(\n","    model,\n","    model_args,\n","    train_dataset=train_dataset,\n","    eval_dataset=validation_dataset,\n","    data_collator=data_collator,\n","    tokenizer=tokenizer,\n","    compute_metrics=compute_metrics\n",")"],"metadata":{"id":"a5QUp-YKM_zW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["trainer.train()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":495,"referenced_widgets":["f27e31fd734644248bbb1c4b75f26ecf","048982b39273448fbab6ac83d4796d1e","3d244c40db0c4639bf161b618026dc30","88dae6916890412da4c68df368457718","860483f584e048dca0bdd02af2d49d92","52364c842fdf403aa4aaff930416ace1","8f0e5403b7a44d2b842bfda40a1a1715","595d932a86d24e37a22c53e93d1b4069","5971843c25b4451db83a257a08d5c423","7a0798b553504bcf8a53c9a4ea751ae9","0fa3fad76ecc4ca0b2413bdae0190acb"]},"id":"31y53X1PNZwS","outputId":"26e4ac85-1044-4a6d-9f17-bcfca4ec7d0e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["You're using a T5TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='300' max='300' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [300/300 01:53, Epoch 10/10]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Gen Len</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>No log</td>\n","      <td>0.168520</td>\n","      <td>69.153000</td>\n","      <td>17.041700</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>No log</td>\n","      <td>0.153269</td>\n","      <td>74.110900</td>\n","      <td>17.116700</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>No log</td>\n","      <td>0.158066</td>\n","      <td>72.132800</td>\n","      <td>17.058300</td>\n","    </tr>\n","    <tr>\n","      <td>4</td>\n","      <td>No log</td>\n","      <td>0.158588</td>\n","      <td>74.159200</td>\n","      <td>17.058300</td>\n","    </tr>\n","    <tr>\n","      <td>5</td>\n","      <td>No log</td>\n","      <td>0.157569</td>\n","      <td>74.474900</td>\n","      <td>17.166700</td>\n","    </tr>\n","    <tr>\n","      <td>6</td>\n","      <td>No log</td>\n","      <td>0.161030</td>\n","      <td>74.597800</td>\n","      <td>17.100000</td>\n","    </tr>\n","    <tr>\n","      <td>7</td>\n","      <td>No log</td>\n","      <td>0.164639</td>\n","      <td>74.778500</td>\n","      <td>17.100000</td>\n","    </tr>\n","    <tr>\n","      <td>8</td>\n","      <td>No log</td>\n","      <td>0.168339</td>\n","      <td>74.097400</td>\n","      <td>17.125000</td>\n","    </tr>\n","    <tr>\n","      <td>9</td>\n","      <td>No log</td>\n","      <td>0.167091</td>\n","      <td>74.765500</td>\n","      <td>17.083300</td>\n","    </tr>\n","    <tr>\n","      <td>10</td>\n","      <td>No log</td>\n","      <td>0.166775</td>\n","      <td>74.801300</td>\n","      <td>17.083300</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f27e31fd734644248bbb1c4b75f26ecf"}},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=300, training_loss=0.0757621955871582, metrics={'train_runtime': 117.034, 'train_samples_per_second': 40.843, 'train_steps_per_second': 2.563, 'total_flos': 95435119411200.0, 'train_loss': 0.0757621955871582, 'epoch': 10.0})"]},"metadata":{},"execution_count":25}]},{"cell_type":"markdown","source":["## Saving the Fine Tuned Transformer"],"metadata":{"id":"-dTlkZUfPX1U"}},{"cell_type":"code","source":["trainer.save_model(\"FineTunedTransformer\")"],"metadata":{"id":"sJwbRg84Nd2H"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Perform Translation on Test Datset"],"metadata":{"id":"uccJodCyPhxK"}},{"cell_type":"code","source":["test_results = trainer.predict(test_dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":17},"id":"CLRxGNjLPghZ","outputId":"538ebde4-87c0-4fe3-f5f9-90d600502b26"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":[]},"metadata":{}}]},{"cell_type":"code","source":["print(\"Test Bleu Score: \", test_results.metrics[\"test_bleu\"])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2jCTg01uQM3w","outputId":"4c916e40-f214-4bef-da19-d50da0cad188"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Test Bleu Score:  75.2502\n"]}]},{"cell_type":"markdown","source":["## Generate Prediction Sentences"],"metadata":{"id":"t-CiCPMtUxvY"}},{"cell_type":"code","source":["\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GllhuPmzAm2j","outputId":"2a0dbc41-3a74-42cb-f2d3-03f42d61ace2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(32128, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",")"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["predictions = []\n","test_input = test_dataset[TRANSLATION]\n","\n","for input_text in tqdm(test_input):\n","    source_sentence = input_text[PORTUGUESE]\n","    encoded_source = tokenizer(source_sentence,\n","                               return_tensors=PORTUGUESE,\n","                               padding=True,\n","                               truncation=True)\n","    encoded_source.to(device)  # Move input tensor to the same device as the model\n","\n","    translated = model.generate(**encoded_source)\n","\n","    predictions.append([tokenizer.decode(t, skip_special_tokens=True) for t in translated][0])\n","\n","# Move the model back to CPU if needed\n","model.to(\"cpu\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zt9eMt5tUM-R","outputId":"2310cdf3-31b7-4548-bcd9-9d713376778d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 67/67 [00:31<00:00,  2.13it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(32128, 768)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(32128, 768)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","              (relative_attention_bias): Embedding(32, 12)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-11): 11 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=768, out_features=768, bias=False)\n","              (k): Linear(in_features=768, out_features=768, bias=False)\n","              (v): Linear(in_features=768, out_features=768, bias=False)\n","              (o): Linear(in_features=768, out_features=768, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=768, out_features=3072, bias=False)\n","              (wo): Linear(in_features=3072, out_features=768, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=768, out_features=32128, bias=False)\n",")"]},"metadata":{},"execution_count":31}]},{"cell_type":"code","source":["y_true_en = []\n","y_true_pt = []\n","\n","for input_text in tqdm(test_input):\n","    y_true_pt.append(input_text[PORTUGUESE])\n","    y_true_en.append(input_text[ENGLISH])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P1CTBrXhUlVn","outputId":"f41028e5-ee19-4ffc-e7c6-01af767338be"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 67/67 [00:00<00:00, 56531.56it/s]\n"]}]},{"cell_type":"code","source":["output_df = pd.DataFrame({\"y_true_port\": y_true_pt, \"y_true_eng\": y_true_en, \"predicted_text\": predictions})\n","output_df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":423},"id":"aMgdAMML6BZi","outputId":"f6dff64a-f056-4c76-c85d-51b30742d08c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                          y_true_port  \\\n","0   Eles estão restaurando uma mansão histórica pa...   \n","1   A arquitetura neoclássica da biblioteca é impo...   \n","2                   A cultura local é rica e diversa.   \n","3     A arte de rua nesta área é colorida e vibrante.   \n","4   Estamos explorando as ruínas antigas de uma ci...   \n","..                                                ...   \n","62  Estamos criando uma instalação de arte sonora ...   \n","63  O restaurante serve pratos internacionais deli...   \n","64  Eles estão organizando um festival de cinema i...   \n","65  Estamos planejando uma viagem de observação de...   \n","66  A arquitetura renascentista italiana é uma obr...   \n","\n","                                           y_true_eng  \\\n","0   They're restoring a historic mansion to preser...   \n","1   The neoclassical architecture of the library i...   \n","2              The local culture is rich and diverse.   \n","3   The street art in this area is colorful and vi...   \n","4   We're exploring the ancient ruins of a lost ci...   \n","..                                                ...   \n","62  We're creating an interactive sound art instal...   \n","63  The restaurant serves delicious international ...   \n","64   They're organizing an independent film festival.   \n","65               We're planning a bird-watching trip.   \n","66  Italian Renaissance architecture is a work of ...   \n","\n","                                       predicted_text  \n","0   They're restoring a historic mansão to preserv...  \n","1   The neoclassical architecture of the library i...  \n","2              The local culture is rich and diverse.  \n","3    Street art in this area is colorful and vibrant.  \n","4   We're exploring the ancient ruins of a lost ci...  \n","..                                                ...  \n","62  We're creating an interactive sound art instal...  \n","63  The restaurant serves delicious international ...  \n","64   They're organizing an independent film festival.  \n","65            We're planning a bird observation trip.  \n","66  Italian Renaissance architecture is an artwork...  \n","\n","[67 rows x 3 columns]"],"text/html":["\n","\n","  <div id=\"df-5d7ef170-5a33-4733-b2e7-afff0de51a67\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>y_true_port</th>\n","      <th>y_true_eng</th>\n","      <th>predicted_text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Eles estão restaurando uma mansão histórica pa...</td>\n","      <td>They're restoring a historic mansion to preser...</td>\n","      <td>They're restoring a historic mansão to preserv...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>A arquitetura neoclássica da biblioteca é impo...</td>\n","      <td>The neoclassical architecture of the library i...</td>\n","      <td>The neoclassical architecture of the library i...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>A cultura local é rica e diversa.</td>\n","      <td>The local culture is rich and diverse.</td>\n","      <td>The local culture is rich and diverse.</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>A arte de rua nesta área é colorida e vibrante.</td>\n","      <td>The street art in this area is colorful and vi...</td>\n","      <td>Street art in this area is colorful and vibrant.</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Estamos explorando as ruínas antigas de uma ci...</td>\n","      <td>We're exploring the ancient ruins of a lost ci...</td>\n","      <td>We're exploring the ancient ruins of a lost ci...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>62</th>\n","      <td>Estamos criando uma instalação de arte sonora ...</td>\n","      <td>We're creating an interactive sound art instal...</td>\n","      <td>We're creating an interactive sound art instal...</td>\n","    </tr>\n","    <tr>\n","      <th>63</th>\n","      <td>O restaurante serve pratos internacionais deli...</td>\n","      <td>The restaurant serves delicious international ...</td>\n","      <td>The restaurant serves delicious international ...</td>\n","    </tr>\n","    <tr>\n","      <th>64</th>\n","      <td>Eles estão organizando um festival de cinema i...</td>\n","      <td>They're organizing an independent film festival.</td>\n","      <td>They're organizing an independent film festival.</td>\n","    </tr>\n","    <tr>\n","      <th>65</th>\n","      <td>Estamos planejando uma viagem de observação de...</td>\n","      <td>We're planning a bird-watching trip.</td>\n","      <td>We're planning a bird observation trip.</td>\n","    </tr>\n","    <tr>\n","      <th>66</th>\n","      <td>A arquitetura renascentista italiana é uma obr...</td>\n","      <td>Italian Renaissance architecture is a work of ...</td>\n","      <td>Italian Renaissance architecture is an artwork...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>67 rows × 3 columns</p>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5d7ef170-5a33-4733-b2e7-afff0de51a67')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","\n","\n","\n","    <div id=\"df-bda94fb4-b80b-4718-bd61-558371f67607\">\n","      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bda94fb4-b80b-4718-bd61-558371f67607')\"\n","              title=\"Suggest charts.\"\n","              style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","      </button>\n","    </div>\n","\n","<style>\n","  .colab-df-quickchart {\n","    background-color: #E8F0FE;\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: #1967D2;\n","    height: 32px;\n","    padding: 0 0 0 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: #E2EBFA;\n","    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: #174EA6;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","    background-color: #3B4455;\n","    fill: #D2E3FC;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart:hover {\n","    background-color: #434B5C;\n","    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","    fill: #FFFFFF;\n","  }\n","</style>\n","\n","    <script>\n","      async function quickchart(key) {\n","        const containerElement = document.querySelector('#' + key);\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      }\n","    </script>\n","\n","      <script>\n","\n","function displayQuickchartButton(domScope) {\n","  let quickchartButtonEl =\n","    domScope.querySelector('#df-bda94fb4-b80b-4718-bd61-558371f67607 button.colab-df-quickchart');\n","  quickchartButtonEl.style.display =\n","    google.colab.kernel.accessAllowed ? 'block' : 'none';\n","}\n","\n","        displayQuickchartButton(document);\n","      </script>\n","      <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5d7ef170-5a33-4733-b2e7-afff0de51a67 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5d7ef170-5a33-4733-b2e7-afff0de51a67');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":39}]},{"cell_type":"markdown","source":["## Loading the stored Model and using it for translation"],"metadata":{"id":"3a0ovGBKpIN-"}},{"cell_type":"code","source":["ft_model_tokenizer = T5Tokenizer.from_pretrained(\"FineTunedTransformer\")\n","ft_model = T5ForConditionalGeneration.from_pretrained(\"FineTunedTransformer\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PfqgbDIEpHhh","outputId":"169abe88-636c-4447-a988-f5c673a87858"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["You are using the legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This means that tokens that come after special tokens will not be properly handled. We recommend you to read the related pull request available at https://github.com/huggingface/transformers/pull/24565\n"]}]},{"cell_type":"code","source":["ft_prediction = []\n","\n","for sentence in tqdm(x_test):\n","    encoded_text = ft_model_tokenizer(sentence, return_tensors=PORTUGUESE, padding=True, truncation=True)\n","    translated = ft_model.generate(**encoded_text)\n","    ft_prediction.append([tokenizer.decode(t, skip_special_tokens=True) for t in translated][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b05VhEo7pd4g","outputId":"b1e2d177-7b6f-4965-8cb8-f535e0a34d38"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 0/67 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","100%|██████████| 67/67 [01:19<00:00,  1.19s/it]\n"]}]},{"cell_type":"code","source":["ft_prediction"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gYyaiW4lCEk3","outputId":"ee5052ea-9e63-49f4-e32b-ebc32682f356"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[\"They're restoring a historic mansão to preserve heritage.\",\n"," 'The neoclassical architecture of the library is impressive',\n"," 'The local culture is rich and diverse.',\n"," 'Street art in this area is colorful and vibrant.',\n"," \"We're exploring the ancient ruins of a lost civilization.\",\n"," \"She's painting an urban landscape in a realistic style\",\n"," \"I'm tired after a long day.\",\n"," \"We're exploring forest trails to study ecology\",\n"," 'Teamwork is essential.',\n"," 'The adventure waits for us beyond the horizon.',\n"," 'Electronic music creates unique sound environments.',\n"," \"We're planning a camping trip near the lake.\",\n"," 'Georgian architecture features symmetry and refined',\n"," 'The exciting soccer game attracted a great audience.',\n"," 'The potent sun paints the sky with warm tones.',\n"," \"We're organizing a charity event to help the needy.\",\n"," \"We're creating a visual art installation.\",\n"," \"They're decorating the house for Christmas.\",\n"," 'Baroque architecture features detailed and dramatic o',\n"," \"We're experimenting with local cuisine at different restaurant\",\n"," \"We're participating in a ceramic workshop in an artisanal \",\n"," 'The night sky is full of stars.',\n"," 'The contemporary art museum is inspiring.',\n"," 'The restaurant offers delicious dishes.',\n"," \"They're leading a river and lake cleanup project\",\n"," \"I'm thinking of start running.\",\n"," 'The museum has amazing exhibitions.',\n"," 'The painting in the art gallery is impressive.',\n"," \"She's experimenting with oil painting techniques.\",\n"," 'The caudal river is perfect for exciting raftting.',\n"," 'The artist is creating an abstract sculpture.',\n"," 'The park is a great place to relax.',\n"," \"I'm planning a backpacking trip.\",\n"," \"They're organizing a charity event.\",\n"," \"She's painting an abstract portrait with vibrant colors.\",\n"," \"They're leading a cleanup project to improve the\",\n"," 'Spanish colonial architecture is an important part of history.',\n"," \"Historic architecture reflects the city's past.\",\n"," 'Sustainable architecture prioritizes ecological materials and ener',\n"," 'The sunset over the mountains is an unforgettable specta',\n"," \"She's dancing with grace and elegance.\",\n"," 'The architecture of the medieval castelo is a trip to the past.',\n"," \"We're watching an improvisation theater performance.\",\n"," 'They are building a new medical center.',\n"," \"We're watching a classic opera at the renowned thea\",\n"," \"I'm going to start a new job next week.\",\n"," 'The house has a charming garden.',\n"," 'French colonial architecture is a remarkable influence in certain re',\n"," \"We're exploring untouched beaches of a tropical paradise\",\n"," 'The fresh products market offers a healthy variety of',\n"," \"We're having a picnic at the beach.\",\n"," \"I'm looking forward to the classical music concert.\",\n"," \"We're going to watch a comedy movie.\",\n"," \"They're planting flowers in a community garden.\",\n"," \"They're decorating the house for Christmas festivities.\",\n"," \"We're going on a camping trip on a deserted island.\",\n"," 'The architecture of the temple is a manifestation of spirituality.',\n"," \"I'm going to prepare a special dinner for the family\",\n"," 'The city is full of life.',\n"," 'The local food market offers fresh products from the region',\n"," 'She has a charming smile.',\n"," \"We're exploring the architecture of historic castles.\",\n"," \"We're creating an interactive sound art installation.\",\n"," 'The restaurant serves delicious international dishes.',\n"," \"They're organizing an independent film festival.\",\n"," \"We're planning a bird observation trip.\",\n"," 'Italian Renaissance architecture is an artwork itself.']"]},"metadata":{},"execution_count":43}]},{"cell_type":"code","source":[],"metadata":{"id":"9Lh1Ne2OCKat"},"execution_count":null,"outputs":[]}]}